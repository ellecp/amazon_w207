{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Amazon rainforest from space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Section\n",
    "1. Split of test data/training data Justification\n",
    "2. Weather models (Multi-classifier single labels)\n",
    "3. Single Label Land Approach\n",
    "4. Multi-label land approach\n",
    "5. Combined Land/Weather approach\n",
    "\n",
    "\n",
    "Given we are mostly interested in being able to tell where deforestation is occuring, we will simplify the land tags into naturally occuring phenomena \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmccorma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n",
      "C:\\Users\\nmccorma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import random\n",
    "import math\n",
    "# from osgeo import gdal\n",
    "from skimage import io\n",
    "#import imageio\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skimage import transform\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split of test training data\n",
    "We are choosing to split the data 90 to 10 training to test. This is because \n",
    "\n",
    "We are including so much more data in the training set because some of the features are \n",
    "\n",
    "Nick/Wei please build in random shuffle of the data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_labels.csv')\n",
    "def apply_land(land_tags):\n",
    "    land_list=[]\n",
    "    other_tags=['habitation','bare_ground','cultivation','agriculture','blow_down', 'conventional_mine', 'selective_logging', 'slash_burn', 'artisinal_mine', 'blooming']\n",
    "    if 'primary' in land_tags:\n",
    "        land_list.append('primary')\n",
    "    if 'water' in land_tags:\n",
    "        land_list.append(\"water\")\n",
    "    other_present=0\n",
    "    for i in other_tags:\n",
    "        if i in land_tags:\n",
    "            other_present=1\n",
    "            break\n",
    "    if other_present==1:\n",
    "        land_list.append('other')\n",
    "    if land_list == []:\n",
    "        land_list.append('none')\n",
    "    return ' '.join(land_list)\n",
    "\n",
    "#Add a column for weather tags\n",
    "def apply_weather(weather):\n",
    "    if 'partly_cloudy' in weather:\n",
    "        return 'partly_cloudy'\n",
    "    elif 'cloudy' in weather:\n",
    "        return 'cloudy'\n",
    "    elif 'haze' in weather:\n",
    "        return 'haze'\n",
    "    else:\n",
    "        return 'clear'\n",
    "    \n",
    "def add_two_columns(df):\n",
    "    df['weather'] = df.tags.map(apply_weather)\n",
    "    df['land'] = df.tags.map(apply_land)\n",
    "    return df\n",
    "\n",
    "add_two_columns(df)\n",
    "df.to_csv(\"train_labels_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#obtain processed training labels and data\n",
    "labels = pd.read_csv('train_labels_clean.csv')\n",
    "data = pd.read_csv('train_data.csv')\n",
    "# Create training and test sets for weather labels by randomly splitting the original dataset as 90%/10%\n",
    "train_data_weather, test_data_weather, train_labels_weather, test_labels_weather = train_test_split(data, labels.weather, test_size=0.1)\n",
    "# Create training and test sets for land labels by randomly splitting the original dataset as 90%/10%\n",
    "train_data_land, test_data_land, train_labels_land, test_labels_land = train_test_split(data, labels.land, test_size=0.1)\n",
    "# Create training and test sets for multi-label land labels by randomly splitting the original dataset as 90%/10%\n",
    "labels['tags_split'] = labels['land'].map(lambda row: row.split(\" \"))\n",
    "mlb = MultiLabelBinarizer()\n",
    "multi_labels = mlb.fit_transform(labels['tags_split'])\n",
    "train_data_land_multi, test_data_land_multi, train_labels_land_multi, test_labels_land_multi= train_test_split(data, multi_labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather feature identification\n",
    "\n",
    "Weather feature identification is being performed for cloud and haze removal. This facilitates the successive water, land and primary feature identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create Useful fucntions\n",
    "2. Try a variety of models\n",
    "3. Improve on the most successful model preformance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Logistic Regression model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_output(pipeline, scores, train_data, train_label, test_data, test_label):\n",
    "    pipeline.fit(train_data,train_label)\n",
    "    model_predictions=pipeline.predict(test_data)\n",
    "    print(classification_report(test_label,model_predictions))\n",
    "\n",
    "    print(\"Cross-Validation\\n Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)) \n",
    "\n",
    "    print(confusion_matrix(test_label, model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the pipeline for logistics regression\n",
    "LG_model =LogisticRegression()\n",
    "LG_pipeline = Pipeline([\n",
    "    ('LogisticsRegression', LG_model),\n",
    "])\n",
    "\n",
    "LG_scores = cross_val_score(LG_pipeline,\n",
    "                            train_data_weather,\n",
    "                            train_label_weather,\n",
    "                            cv=10,\n",
    "                            scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check output for Logistics Regression\n",
    "model_output(LG_pipeline, LG_scores, train_data_weather, train_label_weather, test_data_weather, test_label_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THis model works okay for clear weather - but not really for anything else. Log Reg probably not the way to go.\n",
    "\n",
    "Which labels is it confusing? Everything for Clear by the look of if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the pipeline for decision tree. Use GridSearchCV to find the best depth for decision tree\n",
    "param_grid = dict(DecisionTrees__max_depth=[5, 10,20,50,100])\n",
    "DT_model=DecisionTreeClassifier(min_samples_leaf=20)\n",
    "DT_pipeline = Pipeline([\n",
    "    ('DecisionTrees', DT_model),\n",
    "])\n",
    "\n",
    "grid_tree = GridSearchCV(DT_pipeline, param_grid)\n",
    "grid_tree.fit(train_data_weather, train_label_weather)\n",
    "tree_preds = grid_tree.predict(test_data_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The best tree parameters are: \" + str(grid_tree.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the pipeline for decision tree with the best depth = 5\n",
    "DT_model_best =DecisionTreeClassifier(min_samples_leaf=20, max_depth=5)\n",
    "DT_pipeline_best = Pipeline([\n",
    "    ('DecisionTrees', DT_model_best),\n",
    "])\n",
    "\n",
    "DT_scores = cross_val_score(DT_pipeline_best,\n",
    "                            train_data_weather,\n",
    "                            train_label_weather,\n",
    "                            cv=10,\n",
    "                            scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check output for Decision Tree\n",
    "model_output(DT_pipeline_best, DT_scores, train_data_weather, train_label_weather, test_data_weather, test_label_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the pipeline for random forest. Use GridSearchCV to find the best parameters \n",
    "param_grid = dict(RandomForest__max_depth=[5, 10,20,50,75],\n",
    "                 RandomForest__n_estimators = [20,50,100,200],\n",
    "                 RandomForest__min_samples_leaf = [2,3,4,5,10])\n",
    "\n",
    "RF_model =RandomForestClassifier()\n",
    "RF_pipeline = Pipeline([\n",
    "    ('RandomForest', RF_model),\n",
    "])\n",
    "\n",
    "grid_forest = GridSearchCV(RF_pipeline, param_grid)\n",
    "grid_forest.fit(train_data_weather, train_label_weather)\n",
    "forest_preds = grid_forest.predict(test_data_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The best tree parameters are: \" + str(grid_forest.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the pipeline for random forest with the best parameters\n",
    "RF_model_best =RandomForestClassifier(n_estimators=200, min_samples_leaf=3,max_depth=10)\n",
    "RF_pipeline_best = Pipeline([\n",
    "    ('RandomForest', RF_model_best),\n",
    "])\n",
    "\n",
    "RF_scores = cross_validation.cross_val_score(RF_pipeline_best, \n",
    "                                          train_data_weather,\n",
    "                                          train_label_weather, \n",
    "                                          cv=10,\n",
    "                                          scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check output for Random Forest\n",
    "model_output(RF_pipeline_best, RF_scores, train_data_weather, train_label_weather, test_data_weather, test_label_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is now a fairly accurate model for the clear and partly cloudy models. Both cloudy and hazy are getting confused with clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Land Models - single label models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the pipeline for random forest. Use GridSearchCV to find the best parameters \n",
    "param_grid = dict(RandomForest__max_depth=[5, 10,20,50,75],\n",
    "                 RandomForest__n_estimators = [20,50,100,200],\n",
    "                 RandomForest__min_samples_leaf = [2,3,4,5,10])\n",
    "RF_model_land =RandomForestClassifier()\n",
    "RF_pipeline_land = Pipeline([\n",
    "    ('RandomForest', RF_model_land),\n",
    "])\n",
    "\n",
    "grid_forest_land = GridSearchCV(RF_pipeline_land, param_grid)\n",
    "grid_forest_land.fit(train_data_land, train_label_land)\n",
    "forest_preds_land = grid_forest_land.predict(test_data_land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The best tree depth is: \" + str(grid_forest_land.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the pipeline for random forest with the best parameters\n",
    "RF_model_land_best =RandomForestClassifier(n_estimators=100, min_samples_leaf=2,max_depth=10)\n",
    "RF_pipeline_land_best = Pipeline([\n",
    "    ('RandomForest', RF_model_land_best),\n",
    "])\n",
    "\n",
    "RF_land_scores = cross_validation.cross_val_score(RF_pipeline_land_best, \n",
    "                                          train_data_land,\n",
    "                                          train_label_land, \n",
    "                                          cv=10,\n",
    "                                          scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check output for Random Forest\n",
    "model_output(RF_pipeline_land_best, RF_land_scores, train_data_land, train_label_land, test_data_land, test_label_land)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The model does extremely badly on picking up models with water - it is fairly efficient at picking up primar and primary tags vs other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly not a good model, as by forcing the labels to separate we lose all the predictive power contained in other labels. I.e. what's in a primary water image, will hopefully help use to predict whats in a water other tag as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is Wei's crossvalidation attempt. There is a bug that I didn't get time to fix. If someone can help that would be great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the pipeline for random forest. Use GridSearchCV to find the best depth \n",
    "param_grid = {'estimator__max_depth':[5,10,20,50,75], \n",
    "              'estimator__n_estimators':[20,50,100,200],\n",
    "              'estimator__min_samples_leaf':[2,3,4,5,10]}\n",
    "\n",
    "DT_model_land_multi = OneVsRestClassifier(RandomForestClassifier())\n",
    "\n",
    "grid_forest_land_multi = GridSearchCV(DT_model_land_multi, param_grid)\n",
    "grid_forest_land_multi.fit(train_data_land_multi, train_label_land_multi)\n",
    "forest_preds_land_multi = grid_forest_land_multi.predict(test_data_land_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The best tree parameters are: \" + str(grid_forest_land_multi.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the pipeline for random forest with the best parameters\n",
    "DT_model_land_multi_best =OneVsRestClassifier(RandomForestClassifier(n_estimators=200, min_samples_leaf=4,max_depth=50))\n",
    "\n",
    "DT_land_multi_pipeline = Pipeline([\n",
    "    ('RandomForest', DT_model_land_multi_best),\n",
    "])\n",
    "\n",
    "DT_land_multi_scores = cross_validation.cross_val_score(DT_model_land_multi_best, \n",
    "                                          train_data_land_multi,\n",
    "                                          train_label_land_multi, \n",
    "                                          cv=10,\n",
    "                                          scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check output for Random Forest\n",
    "model_output_multi(DT_land_multi_pipeline, DT_land_multi_scores, train_data_land_multi, test_label_land_multi, test_data_land_multi, test_label_land_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the old code. Leave here for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVR with RandomForestClassifier estimator: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.73      0.77       210\n",
      "          1       0.85      0.82      0.83      1551\n",
      "          2       0.97      0.99      0.98      3738\n",
      "          3       0.82      0.59      0.69       714\n",
      "\n",
      "avg / total       0.92      0.89      0.90      6213\n",
      "\n",
      "Cross-Validation\n",
      " Accuracy: 0.77 (+/- 0.00)\n",
      "Confusion Matrix\n",
      "[[ 160    7   38    5]\n",
      " [   9 1264  273    5]\n",
      " [  26  207 2019    3]\n",
      " [  14    2    6   10]]\n",
      "OVR with DecisionTreeClassifier estimator: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.69      0.70       210\n",
      "          1       0.80      0.78      0.79      1551\n",
      "          2       0.97      0.98      0.98      3738\n",
      "          3       0.64      0.57      0.61       714\n",
      "\n",
      "avg / total       0.88      0.87      0.88      6213\n",
      "\n",
      "Cross-Validation\n",
      " Accuracy: 0.69 (+/- 0.01)\n",
      "Confusion Matrix\n",
      "[[ 168   11   24    7]\n",
      " [  24 1202  323    2]\n",
      " [  47  279 1924    5]\n",
      " [  17    2    6    7]]\n"
     ]
    }
   ],
   "source": [
    "def ovr_model(estimator, data_train,labels_train,data_test,labels_test):\n",
    "    model=OneVsRestClassifier(estimator).fit(data_train,labels_train)\n",
    "    model_predict=model.predict(data_test)\n",
    "    print('OVR with ' + str(model.get_params().get('estimator'))[0:str(model.get_params().get('estimator')).find('(')]+' estimator: ')\n",
    "    print(classification_report(labels_test,model_predict))\n",
    "    cross_validation(model, data_train, labels_train)\n",
    "    confusion_mat(labels_test.argmax(axis=1), model_predict.argmax(axis=1))\n",
    "ovr_model(RandomForestClassifier(n_estimators=50,max_depth=50, min_samples_leaf=2), train_data_land_multi,train_labels_land_multi,test_data_land_multi,test_labels_land_multi)\n",
    "ovr_model(DecisionTreeClassifier(max_depth=50, min_samples_leaf=10), train_data_land_multi,train_labels_land_multi,test_data_land_multi,test_labels_land_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Chain with RandomForestClassifier base estimator: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.73      0.78       210\n",
      "          1       0.85      0.82      0.84      1551\n",
      "          2       0.97      0.99      0.98      3738\n",
      "          3       0.83      0.60      0.70       714\n",
      "\n",
      "avg / total       0.92      0.90      0.91      6213\n",
      "\n",
      "Cross-Validation\n",
      " Accuracy: 0.77 (+/- 0.00)\n",
      "Confusion Matrix\n",
      "[[ 154   13   33   10]\n",
      " [   5 1276  270    0]\n",
      " [  18  206 2024    7]\n",
      " [   8    2    5   17]]\n",
      "Classifier Chain with DecisionTreeClassifier base estimator: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.71      0.71       210\n",
      "          1       0.80      0.77      0.79      1551\n",
      "          2       0.97      0.98      0.97      3738\n",
      "          3       0.63      0.55      0.59       714\n",
      "\n",
      "avg / total       0.88      0.87      0.87      6213\n",
      "\n",
      "Cross-Validation\n",
      " Accuracy: 0.71 (+/- 0.01)\n",
      "Confusion Matrix\n",
      "[[ 151   20   32    7]\n",
      " [  21 1192  336    2]\n",
      " [  37  269 1942    7]\n",
      " [  11    3    4   14]]\n"
     ]
    }
   ],
   "source": [
    "def classifier_chain_model(estimator, data_train,labels_train,data_test,labels_test):\n",
    "    model = ClassifierChain(estimator).fit(data_train, labels_train)\n",
    "    model_predict=model.predict(data_test)\n",
    "    print('Classifier Chain with ' + str(model.get_params().get('base_estimator'))[0:str(model.get_params().get('base_estimator')).find('(')]+' base estimator: ')\n",
    "    print(classification_report(labels_test,model_predict))\n",
    "    cross_validation(model, data_train, labels_train)\n",
    "    confusion_mat(labels_test.argmax(axis=1), model_predict.argmax(axis=1))\n",
    "classifier_chain_model(RandomForestClassifier(n_estimators=50,max_depth=50, min_samples_leaf=2), train_data_land_multi,train_labels_land_multi,test_data_land_multi,test_labels_land_multi)\n",
    "classifier_chain_model(DecisionTreeClassifier(max_depth=50, min_samples_leaf=10), train_data_land_multi,train_labels_land_multi,test_data_land_multi,test_labels_land_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Neighbors: 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.47      0.46       210\n",
      "          1       0.60      0.59      0.59      1551\n",
      "          2       0.96      0.95      0.95      3738\n",
      "          3       0.38      0.35      0.36       714\n",
      "\n",
      "avg / total       0.78      0.78      0.78      6213\n",
      "\n",
      "Cross-Validation\n",
      " Accuracy: 0.53 (+/- 0.00)\n",
      "Confusion Matrix\n",
      "[[  99   61   46    4]\n",
      " [  76  915  557    3]\n",
      " [  42  547 1654   12]\n",
      " [   8    6   10    8]]\n",
      "K-Neighbors: 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.46      0.55       210\n",
      "          1       0.68      0.63      0.65      1551\n",
      "          2       0.96      0.98      0.97      3738\n",
      "          3       0.63      0.25      0.36       714\n",
      "\n",
      "avg / total       0.84      0.79      0.80      6213\n",
      "\n",
      "Cross-Validation\n",
      " Accuracy: 0.60 (+/- 0.01)\n",
      "Confusion Matrix\n",
      "[[  99   47   54   10]\n",
      " [  28  975  546    2]\n",
      " [  20  406 1822    7]\n",
      " [   8    3   11   10]]\n",
      "K-Neighbors: 10\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.34      0.47       210\n",
      "          1       0.75      0.58      0.66      1551\n",
      "          2       0.96      0.98      0.97      3738\n",
      "          3       0.76      0.20      0.32       714\n",
      "\n",
      "avg / total       0.88      0.77      0.80      6213\n",
      "\n",
      "Cross-Validation\n",
      " Accuracy: 0.61 (+/- 0.01)\n",
      "Confusion Matrix\n",
      "[[ 102   35   62   11]\n",
      " [  29  903  617    2]\n",
      " [  27  264 1957    7]\n",
      " [   7    2   13   10]]\n",
      "K-Neighbors: 12\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.37      0.50       210\n",
      "          1       0.74      0.58      0.65      1551\n",
      "          2       0.96      0.98      0.97      3738\n",
      "          3       0.77      0.20      0.32       714\n",
      "\n",
      "avg / total       0.87      0.77      0.80      6213\n",
      "\n",
      "Cross-Validation\n",
      " Accuracy: 0.61 (+/- 0.01)\n",
      "Confusion Matrix\n",
      "[[ 102   40   55   13]\n",
      " [  26  905  618    2]\n",
      " [  26  281 1942    6]\n",
      " [   6    1   16    9]]\n",
      "K-Neighbors: 13\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.40      0.52       210\n",
      "          1       0.71      0.64      0.67      1551\n",
      "          2       0.95      0.99      0.97      3738\n",
      "          3       0.75      0.21      0.33       714\n",
      "\n",
      "avg / total       0.86      0.79      0.81      6213\n",
      "\n",
      "Cross-Validation\n",
      " Accuracy: 0.61 (+/- 0.01)\n",
      "Confusion Matrix\n",
      "[[  92   50   58   10]\n",
      " [  14  987  549    1]\n",
      " [  17  346 1889    3]\n",
      " [   5    1   19    7]]\n"
     ]
    }
   ],
   "source": [
    "def k_neighbors_model(k,data_train,labels_train,data_test,labels_test):\n",
    "    model = KNeighborsClassifier(n_neighbors=k, algorithm='ball_tree').fit(data_train, labels_train)\n",
    "    model_predict=model.predict(data_test)\n",
    "    print(classification_report(labels_test,model_predict))\n",
    "    cross_validation(model, data_train, labels_train)\n",
    "    confusion_mat(labels_test.argmax(axis=1), model_predict.argmax(axis=1))\n",
    "for i in [1,5,10,12,13]:\n",
    "    print(\"K-Neighbors: \" + str(i))\n",
    "    k_neighbors_model(i,train_data_land_multi,train_labels_land_multi,test_data_land_multi,test_labels_land_multi)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now doing a better job at picking up the rare labels, though it struggles a lot with the water label. \n",
    "It is mostly good at detecting the primary label because it appears so often, though it does a relatively good job with the other label, and the none label (which should mostly be used for cloudly image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does well at picking clear, cloudy, primary and not much else. To better identify roads, and water edge extraction may \n",
    "help. We're also not taking advantage of correlation with the model here.\n",
    "\n",
    "Interestingly the model isn't picking too many false positives (i.e. precision), but is picking a lot of false negatives(i.e. recall). This suggests we need to build more features to pick up land masses, roads and waters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of scope\n",
    "Try Convultional Neural Networks\n",
    "Ask June for help in Set-up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
