{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Amazon rainforest from space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of Assignment\n",
    "There are three types of tags in this assignment:\n",
    "<br>\n",
    "1) Weather (Cloudly, Partly Cloudy, Hazy, Clear) - every item has only one of these ones\n",
    "<br>\n",
    "2) Easy to identify tags Primary (forest), agricultural, habitation, roads, water, cultivation, bare ground,\n",
    "<br>\n",
    "3) Hard Labels - Slash & Burn, selective logging, blooms, and mine types\n",
    "<br>\n",
    "\n",
    "Given we are mostly interested in being able to tell where deforestation is occuring, we will simplify the land tags into naturally occuring phenomena \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Libraries [Requires cleaning]\n",
    "### Required libraries\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from collections import Counter, defaultdict\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import random\n",
    "# from osgeo import gdal\n",
    "from skimage import io\n",
    "#import imageio\n",
    "from spectral import get_rgb\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skimage import transform\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Satellite Images\n",
    "There're 2 image formats provided for training and testing: jpg and tif. The tif format contains additional dimensions outside of the jpg RGB dimensional constraints which enable us to extract the infrared spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##set path\n",
    "train_path1='train_jpg/'\n",
    "train_path2='train_tif/'\n",
    "test_path1='test_jpg/'\n",
    "\n",
    "#obtain training labels\n",
    "df = pd.read_csv('train_labels.csv')\n",
    "\n",
    "#retrieve jpg data - compress from 256x256 to 64x64 for faster training [remove constraint in final product]\n",
    "data_jpgs=np.zeros((40000,64,64,3))\n",
    "\n",
    "##retrieve jpg data\n",
    "def read_image(image_str):\n",
    "    read_img = plt.imread(train_path1+image_str)\n",
    "    read_img=read_img[:,:,:3]\n",
    "    jpg_img=transform.resize(read_img, (64,64,3))\n",
    "    return jpg_img\n",
    "for i in range(40000):\n",
    "    data_jpgs[i,:,:,:]=read_image(\"train_\"+str(i)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve tif format satellite images - compress from 256x256 to 64x64 for faster training [remove constraint in final product]\n",
    "def extract_identifier(image_str):\n",
    "    read_img = io.imread(train_path2+image_str)\n",
    "    tif_img=transform.resize(read_img, (64,64,4))\n",
    "    return tif_img\n",
    "\n",
    "#4th dimension of GeoTiff contains near-infrared spectrum\n",
    "tif_data=np.zeros((40000,64,64,4))\n",
    "for i in range(40000):\n",
    "    tif_data[i,:,:,:]=extract_identifier(\"train_\"+str(i)+\".tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Analysis, Visualization, & Correlation\n",
    "\n",
    "Each picture can have multiple labels. There is a varying visibility between the images.  \n",
    "\n",
    "As a result, visibility is a key feature which needs to be identified and cleared for additional feature identification. Visibility is categorized in levels by cloud cover - haze, partly cloudy, cloudy and clear.\n",
    "\n",
    "Primary label refers to primary rainforest. Water refers to rivers and large water bodies.\n",
    "\n",
    "Human interference & civilization can be categorized into road, agriculture, habitation, selective logging, artisal mine, slash burn, blow down, conventional mine, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the goal of our project is to automatically categorize landscape, which prepares for the prediction of rainforest diminishing rate, we categorize the original labels into three main areas:\n",
    "* Weather due to cloud cover (haze, partly cloudy, haze)\n",
    "* Road/water\n",
    "* Primary\n",
    "* Other tags\n",
    "\n",
    "All other tags will be removed to reduce the complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a column for land tags\n",
    "def apply_land(land_tags):\n",
    "    if 'primary' in land_tags:\n",
    "        return 'primary'\n",
    "    elif 'water' in land_tags:\n",
    "        return 'water'\n",
    "    else:\n",
    "        return 'other'\n",
    "df['land'] = df.tags.map(apply_land)\n",
    "df_tags = df['land'].tolist()\n",
    "\n",
    "#Add a column to remove tags that are harder to predict\n",
    "def remove_tag(hard):\n",
    "    hard_tags=['blow_down', 'conventional_mine', 'selective_logging', 'slash_burn', 'artisinal_mine', 'blooming']\n",
    "    easier_tags=hard.split()\n",
    "    for i in hard_tags:\n",
    "        try:\n",
    "            easier_tags.remove(i)\n",
    "        except:\n",
    "            pass\n",
    "    easier_tags=' '.join(easier_tags)\n",
    "    return easier_tags\n",
    "df['simpler_tags'] = df.tags.map(remove_tag)\n",
    "\n",
    "#Add a column for weather tags\n",
    "def apply_weather(weather):\n",
    "    if 'partly_cloudy' in weather:\n",
    "        return 'partly_cloudy'\n",
    "    elif 'cloudy' in weather:\n",
    "        return 'cloudy'\n",
    "    elif 'haze' in weather:\n",
    "        return 'haze'\n",
    "    else:\n",
    "        return 'clear'\n",
    "df['weather'] = df.tags.map(apply_weather)\n",
    "df_tags = df['weather'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After adding three more columns, our dataframe looks like this\n",
    "print(df.iloc[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph demonstration of four weather type\n",
    "plt.figure(figsize=(12,12))\n",
    "weather_list = [\"haze\",\"partly_cloudy\",\"cloudy\",\"clear\"]\n",
    "j = 0\n",
    "for i in weather_list:\n",
    "    plt.subplot(2,2,j+1)\n",
    "    image_number = df.loc[df['weather'] == i][:1]['image_name'].values\n",
    "    image_path = train_path1+image_number+\".jpg\"\n",
    "    plt.imshow(plt.imread(image_path[0]))\n",
    "    plt.tight_layout()\n",
    "    plt.title(str(df[df.image_name == image_number[0]].tags.values))  \n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph demonstration of three land type\n",
    "plt.figure(figsize=(12,12))\n",
    "land_list = [\"primary\",\"water\",\"other\"]\n",
    "j = 0\n",
    "for i in land_list:\n",
    "    plt.subplot(2,2,j+1)\n",
    "    image_number = df.loc[df['land'] == i][3:4]['image_name'].values\n",
    "    image_path = train_path1+image_number+\".jpg\"\n",
    "    plt.imshow(plt.imread(image_path[0]))\n",
    "    plt.tight_layout()\n",
    "    plt.title(str(df[df.image_name == image_number[0]].tags.values))  \n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "Image visibility varies. Images with out haze and cloud are much easier to identify the land type. \n",
    "\n",
    "Each picture has multiple labels except for 'Cloudy' tag, which does not appear with other labels. 'Water' is sometimes hard to identify in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display counts of weather and land labels\n",
    "df[\"combined_tags\"] = df[\"weather\"] + \" \" + df[\"land\"]\n",
    "labels = df['combined_tags'].apply(lambda x: x.split(' '))\n",
    "all_tags = [item for sublist in list(labels.values) for item in sublist]\n",
    "labels_s = pd.Series(all_tags).value_counts() # To sort them by count\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.barplot(x=labels_s, y=labels_s.index, orient='h', order = ['haze', 'partly_cloudy', 'cloudy', 'clear','primary', 'water', 'other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "The majority pictures have 'Clear' weather and 'Primary' land type. \n",
    "\n",
    "There are very few pictures have the 'Water' tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display correlation between labels \n",
    "counts = defaultdict(int)\n",
    "for l in labels:\n",
    "    for l2 in l:\n",
    "        counts[l2] += 1\n",
    "\n",
    "com = np.zeros([len(counts)]*2)\n",
    "for i, l in enumerate(list(counts.keys())):\n",
    "    for i2, l2 in enumerate(list(counts.keys())):\n",
    "        c = 0\n",
    "        cy = 0\n",
    "        for row in labels.values:\n",
    "            if l in row:\n",
    "                c += 1\n",
    "                if l2 in row: cy += 1\n",
    "        com[i, i2] = cy / c\n",
    "\n",
    "data=[go.Heatmap(z=com, x=list(counts.keys()), y=list(counts.keys()))]\n",
    "layout=go.Layout(height=600, width=600, title='Co-occurence matrix of training labels')\n",
    "fig=dict(data=data, layout=layout)\n",
    "py.iplot(data, filename='train-com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "'Primary' land type has high correlation with all weather tags except for \"Cloudy\". Most \"Cloudy\" pictures have \"Other\" land type. \n",
    "\n",
    "\"Water\" land type is highly correlated with \"Clear\" tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static features including volume of colours can be extracted using the following logic:\n",
    "* Green = Trees/Vegetation\n",
    "* Blue = Water\n",
    "* White = Clouds\n",
    "\n",
    "The higher the pixel value, the higher the intensity of the colors. Variance in the colors indicate feature differences in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extract_basic-stats about image\n",
    "stats_flat=np.reshape(data_jpgs,(data_jpgs.shape[0],4096,3))\n",
    "jpg_stats=np.zeros((stats_flat.shape[0],75))\n",
    "for i in range(stats_flat.shape[0]):\n",
    "    jpg_stats[i,0:3]=np.average(stats_flat[i],axis=0)\n",
    "    jpg_stats[i,3:6]=np.var(stats_flat[i],axis=0)\n",
    "    jpg_stats[i,6:9]=np.std(stats_flat[i],axis=0)\n",
    "    kurt_skew=np.zeros((6,))\n",
    "    \n",
    "    for j in range(3):\n",
    "        kurt_skew[j]=scipy.stats.kurtosis(data_jpgs[i,:,:,j].ravel())\n",
    "        kurt_skew[j]=scipy.stats.skew(data_jpgs[i,:,:,j].ravel())\n",
    "    jpg_stats[i,9:15]=kurt_skew\n",
    "    jpg_stats[i,15:35]=np.array(np.histogram(data_jpgs[1,:,:,0],bins=20, range=(0,1))[0])\n",
    "    jpg_stats[i,35:55]=np.array(np.histogram(data_jpgs[1,:,:,1],bins=20, range=(0,1))[0])\n",
    "    jpg_stats[i,55:75]=np.array(np.histogram(data_jpgs[1,:,:,2],bins=20, range=(0,1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The mean color intensity is: ', round(jpg_stats[:,0:3].mean(), 2))\n",
    "plt.hist(jpg_stats[:,0:3])\n",
    "print('The mean color variance is: ', round(jpg_stats[:,3:6].mean(), 3))\n",
    "print('The mean color standard deviation is: ', round(jpg_stats[:,6:9].mean(), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection in the images can be analyzed using the following parameters:\n",
    "* Laplacian outputs the color gradients in the images\n",
    "* Sobel outputs the edges of the color gradients in the x or the y directions\n",
    "\n",
    "The following distributions shows that majority of the pictures may not have large color gradients. As a result, many of the images are dominated by their respective label components and relatively few satellite images contain edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extract edge data from images\n",
    "edge_stats=np.zeros((stats_flat.shape[0],6))\n",
    "for i in range(stats_flat.shape[0]):\n",
    "    edge_stats[i,0]=cv2.Laplacian(data_jpgs[i], cv2.CV_64F).mean()\n",
    "    edge_stats[i,1]=cv2.Laplacian(data_jpgs[i], cv2.CV_64F).var()\n",
    "    edge_stats[i,2]=cv2.Sobel(data_jpgs[i],cv2.CV_64F,1,0,ksize=5).var()\n",
    "    edge_stats[i,3]=cv2.Sobel(data_jpgs[i],cv2.CV_64F,1,0,ksize=5).mean()\n",
    "    edge_stats[i,4]=cv2.Sobel(data_jpgs[i],cv2.CV_64F,0,1,ksize=5).mean()\n",
    "    edge_stats[i,5]=cv2.Sobel(data_jpgs[i],cv2.CV_64F,0,1,ksize=5).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(edge_stats[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(edge_stats[:,3:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training and test sets [jpg]\n",
    "The first 30000 samples will be allocated to the training set while the remaining samples will be allocated to the test set. Randomization is not required since prior ordering is unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)\n",
    "train_labels_jpgs=np.array(df_tags[:30000])\n",
    "\n",
    "train_data_jpgs=np.zeros((len(train_labels_jpgs),64,64,3))\n",
    "for i in range(len(train_labels_jpgs)):\n",
    "    train_data_jpgs[i,:,:,:]=read_image(\"train_\"+str(i)+\".jpg\")\n",
    "\n",
    "\n",
    "test_labels_jpgs=np.array(df_tags[30000:])\n",
    "\n",
    "test_data_jpgs=np.zeros((len(test_labels_jpgs),64,64,3))\n",
    "for i in range(len(test_labels_jpgs)):\n",
    "    test_data_jpgs[i,:,:,:]=read_image(\"train_\"+str(i)+\".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infrared spectrum analysis\n",
    "\n",
    "Extracting the near-infrared spectrum in the images(tif format) enables the identification of \"hot\" surfaces with varying degrees of heat such as: \n",
    "1. Civilization\n",
    "2. Vegetation\n",
    "3. Large bodies of water\n",
    "\n",
    "Water features can be identified by removing the blue frequency from the near-infrared spectrum: (B-IRR)/(B+IRR) \n",
    "\n",
    "Vegetation features can be identified by removing green frequency from the near-infrared spectrum: (IRR-R)/(R+IRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract, vegetation probabilities and water information - show how the data\n",
    "#This take the blue pixels, subtracts the infrared, and divides by the total to indicate water\n",
    "water_tif=(tif_data[:,:,:,0]-tif_data[:,:,:,3])/(tif_data[:,:,:,0]+tif_data[:,:,:,3])\n",
    "#This take the infrared pixels, subtracts the red, and divides by the total to indicate vegetation\n",
    "veg_tif=(tif_data[:,:,:,3]-tif_data[:,:,:,2])/(tif_data[:,:,:,3]+tif_data[:,:,:,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample vegetation feature identification\n",
    "plt.imshow(veg_tif[18573])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample water feature identification\n",
    "plt.imshow(water_tif[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_props=np.zeros((40000,10))\n",
    "for i in range(40000):\n",
    "    #this calculates the ditribution of the index. Lots of values near one indicate lots of trees, \n",
    "    #values between 0-0.4 indicate bare ground\n",
    "    veg_props[i,:]=np.array(np.histogram(veg_tif[i],bins=10, range=(-1,1))[0])\n",
    "water_props=np.zeros((40000,10))\n",
    "for i in range(40000):\n",
    "    water_props[i,:]=np.array(np.histogram(water_tif[i],bins=10, range=(-1,1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_matrix=np.zeros((40000,101))\n",
    "combined_matrix[:,0:10]=veg_props\n",
    "combined_matrix[:,10:20]=water_props\n",
    "combined_matrix[:,20:95]=jpg_stats\n",
    "combined_matrix[:,95:101]=edge_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training and test sets [tif]\n",
    "The first 30000 samples will be allocated to the training set while the remaining samples will be allocated to the test set. Randomization is not required since prior ordering is unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create test and training datatrain_labels=np.array(df_tags[:30000])\n",
    "train_labels=np.array(df_tags[:30000])\n",
    "train_data=combined_matrix[:30000]\n",
    "\n",
    "test_labels=np.array(df_tags[30000:40000])\n",
    "test_data=combined_matrix[30000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal component analysis (PCA)\n",
    "\n",
    "PCA speeds up the training of features by choosing the minimum number of components such that 95% of the variance is retained.\n",
    "\n",
    "A logistic regression model is used to further examine the prediction score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA the training set to potentially reduce the size\n",
    "pca = PCA(.95)\n",
    "pca.fit(train_data)\n",
    "\n",
    "train_data = pca.transform(train_data)\n",
    "test_data = pca.transform(test_data)\n",
    "\n",
    "print('The PCA explained variance ratios for each component are: ', pca.explained_variance_ratio_)\n",
    "print('The number of PCA components chosen are: ', pca.n_components_)\n",
    "\n",
    "\n",
    "#Testing accuracy of logistic Regression with PCA for sample of 1000 images\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "%time logisticRegr.fit(train_data, train_labels)\n",
    "logisticRegr.predict(test_data[0:1000])\n",
    "print('The logistic regression score is:', logisticRegr.score(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather feature identification\n",
    "\n",
    "Weather feature identification is being performed for cloud and haze removal. This facilitates the successive water, land and primary feature identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ovr(estimator, training_data, training_labels, testing_data, testing_labels):\n",
    "    ovr=OneVsRestClassifier(estimator).fit(train_data,train_labels)\n",
    "    ovr_predict=ovr.predict(test_data)\n",
    "    print(classification_report(test_labels,ovr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistics Regression (NOT WORKING WITH PCA)\n",
    "def logistic_regression(training_data, training_labels, testing_data, testing_labels):\n",
    "    model_LG =LogisticRegression()\n",
    "    model_LG.fit(training_data, training_labels)\n",
    "    LG_predictions=model_LG.predict(testing_data)\n",
    "    print(classification_report(testing_labels,LG_predictions))\n",
    "    print('One Vs. Rest Logistic Regression: ')\n",
    "    ovr(model_LG, train_data, train_labels, test_data, test_labels)\n",
    "logistic_regression(train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_tree_model(maxs,data_train,labels_train,data_test,labels_test):\n",
    "    #set the model to take in the k value\n",
    "    model = DecisionTreeClassifier(min_samples_leaf=20, max_depth=maxs)\n",
    "    #fit per the train data\n",
    "    model.fit(data_train, labels_train)\n",
    "    dev_predictions2=model.predict(data_test)\n",
    "    #set by the test data\n",
    "#     score = model.score(data_test, labels_test)\n",
    "    #print the score prettily\n",
    "    return classification_report(labels_test,dev_predictions2), model\n",
    "for i in [5,10,20,50,100]:\n",
    "    print(\"K-branch levels\" + str(i))\n",
    "    classification_rpt, model = dec_tree_model(i,train_data,train_labels,test_data,test_labels)\n",
    "    print(classification_rpt)\n",
    "    print('One Vs. Rest K-branch levels ' + str(i))\n",
    "    ovr(model, train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_model(maxs,data_train,labels_train,data_test,labels_test):\n",
    "    #set the model to take in the k value\n",
    "    model = RandomForestClassifier(n_estimators=20, max_depth=maxs, min_samples_split=2, min_samples_leaf=5)\n",
    "     #fit per the train data\n",
    "    model.fit(data_train, labels_train)\n",
    "    dev_predictions2=model.predict(data_test)\n",
    "    #set by the test data\n",
    "#     score = model.score(data_test, labels_test)\n",
    "    #print the score prettily\n",
    "    return classification_report(labels_test,dev_predictions2), model\n",
    "\n",
    "for i in [5,10,20,50]:\n",
    "    print(\"K-branch levels\" + str(i))\n",
    "    classification_rpt, model = random_forest_model(i,train_data,train_labels,test_data,test_labels)\n",
    "    print(classification_rpt)\n",
    "    print('One Vs. Rest K-branch levels ' + str(i))\n",
    "    ovr(model, train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_weather_model = RandomForestClassifier(n_estimators=10, max_depth=50, min_samples_leaf=20)\n",
    "     #fit per the train data\n",
    "sel_weather_model.fit(train_data, train_labels)\n",
    "dev_predictions2=sel_weather_model.predict(test_data)\n",
    "print(classification_report(test_labels,dev_predictions2))\n",
    "print(confusion_matrix(test_labels,dev_predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a fairly accurate model, but too much of partly cloudly and hazy is getting classified as clear. We might need\n",
    "to split the colour bands up more, to be able to separate the from clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try the simple tags and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags_split'] = df['simpler_tags'].map(lambda row: row.split(\" \"))\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(df['tags_split'])\n",
    "\n",
    "train_labels=labels[:30000]\n",
    "\n",
    "test_labels=labels[30000:40000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does well at picking clear, cloudy, primary and not much else. To better identify roads, and water edge extraction may \n",
    "help. We're also not taking advantage of correlation with the model here.\n",
    "\n",
    "Interestingly the model isn't picking too many false positives (i.e. precision), but is picking a lot of false negatives(i.e. recall). This suggests we need to build more features to pick up land masses, roads and waters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature prediction of clear components\n",
    "Land and water can be extracted using canny edge detection or equivalent. The inputs are haze/cloud cleared train data+labels.\n",
    "\n",
    "[Under construction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def road_water_canny(train_data, train_labels, test_data, test_labels):\n",
    "##Testing water/road feature identification##\n",
    "    #40479 images in df\n",
    "    #13357 images with water and road tags in labels\n",
    "    train_roadwater_data = [i for i, j in zip(train_data, train_labels) if 'water' in j or 'road' in j]\n",
    "    train_roadwater_labels = [j for i, j in zip(train_data, train_labels) if 'water' in j or 'road' in j]\n",
    "    \n",
    "\n",
    "    \n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    \n",
    "    feature_count = 0\n",
    "    positive_test_img = []\n",
    "    plt.figure(figsize=(12,12))\n",
    "    \n",
    "    for i, train_img in enumerate(train_roadwater_data):\n",
    "        \n",
    "        gray_image = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        cannyed_image = cv2.Canny(gray_image, 100, 200)\n",
    "        \n",
    "        try:\n",
    "            plt.subplot(3,3,i+1)\n",
    "            if i < 10:\n",
    "                plt.imshow(cannyed_image)\n",
    "                #plt.title(str(df[df.image_name == df_road_water_images[i]].tags.values))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        predicted_sum = sum(cannyed_image.flatten())\n",
    "        \n",
    "        if predicted_sum > 2.0:\n",
    "            feature_count += 1\n",
    "            positive_train_img.append(train_)\n",
    "        \n",
    "    positive_label_count = len([i for i, j in zip(train_roadwater_, positive_train_img) if i == j])\n",
    "    \n",
    "    return feature_count, positive_label_count\n",
    "    \n",
    "feature_count, positive_label_count = road_water_canny(train_data_jpg, train_labels_jpg, test_data_jpg, test_labels_jpg)\n",
    "print('Total number of images with water/road boundary features', feature_count)\n",
    "print('Correctly predicted labels', positive_label_count)\n",
    "print('Accuracy is: ', positive_label_count/feature_count * 100, '%')\n",
    "print('Remaining images with especially water labels may not have boundaries/features in water or contain too much cloud.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward we've got three clear priorities:\n",
    "\n",
    "Improve the models we have now:\n",
    "1) Improve the classifiers we have by running cross validation on the data, and setting up proper pipelines\n",
    "2) Play with the statistics in the model to see if changing them produces better impacts (i.e. water prediction is only working a third of the time, can we improve it)\n",
    "3) Try other kinds of multi-label models\n",
    "\n",
    "Extract More features:\n",
    "1) We've used a haze remover before to improve picture quality, and a two stage process will let us identify which pictures need it and then extract the land labels so we don't use any information.\n",
    "\n",
    "Try Deep learning:\n",
    "Image feature analysis is some what out of fashion, and most of the successful approaches to this on Kaggle used CNN. \n",
    "June if you could point us in the right direction for how to do this that would be awesome. We've run into memory issues, before using the statistical extraction approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of scope\n",
    "Try Convultional Neural Networks\n",
    "Ask June for help in Set-up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
